{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment №1, part 2\n",
    "\n",
    "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
    "\n",
    "Several comments:\n",
    "* Don't hesitate to ask questions, it's a good practice.\n",
    "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
    "* Blocks of this lab will be graded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 2. Data preprocessing, model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_f20/homeworks_basic/Lab1_ML_pipeline_and_SVM/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 19) (846,)\n",
      "(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n0    85  110  58  106  180  51   6  261  26  28  171  278  998  257  83   9   \n1   249   85  34   53  127  58   6  116  58  17  121  137  197  127  70   3   \n2   747   80  43   68  123  53   7  150  46  19  147  169  327  176  81   7   \n3   609   87  42   60  116  51   6  150  46  19  141  169  324  171  85   2   \n4   698   83  42   71  152  64   7  149  45  19  142  172  331  158  74   2   \n5   407   91  38   75  136  53   6  144  47  19  131  165  305  149  69   1   \n6   365  108  54  105  203  62  11  202  33  23  164  216  608  235  68  12   \n7   227   94  35   66  147  62   9  131  50  18  127  159  258  115  66   8   \n8   436   93  42   64  123  51   7  135  51  18  144  164  262  155  78  16   \n9   497   94  43   82  136  54  10  155  43  19  149  176  359  161  74   1   \n10  318   89  37   51  111  54   5  120  56  17  127  138  213  147  82   7   \n11  222  100  50   81  197  67   6  186  34  22  158  206  531  198  74   6   \n12  409   86  38   86  175  60   9  170  39  21  134  191  433  138  68   1   \n13  836   87  45   66  139  58   8  140  47  18  148  168  294  175  73   3   \n14  247   91  39   83  176  59   7  169  39  20  132  190  426  142  67   0   \n\n    16   17   18  \n0   13  181  182  \n1   20  185  189  \n2   14  179  184  \n3   14  178  182  \n4    2  184  190  \n5    7  186  191  \n6    3  190  200  \n7    7  196  201  \n8   12  185  185  \n9    6  186  197  \n10   4  181  183  \n11   1  197  198  \n12  28  191  199  \n13  12  188  196  \n14  24  192  199  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>85</td>\n      <td>110</td>\n      <td>58</td>\n      <td>106</td>\n      <td>180</td>\n      <td>51</td>\n      <td>6</td>\n      <td>261</td>\n      <td>26</td>\n      <td>28</td>\n      <td>171</td>\n      <td>278</td>\n      <td>998</td>\n      <td>257</td>\n      <td>83</td>\n      <td>9</td>\n      <td>13</td>\n      <td>181</td>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>249</td>\n      <td>85</td>\n      <td>34</td>\n      <td>53</td>\n      <td>127</td>\n      <td>58</td>\n      <td>6</td>\n      <td>116</td>\n      <td>58</td>\n      <td>17</td>\n      <td>121</td>\n      <td>137</td>\n      <td>197</td>\n      <td>127</td>\n      <td>70</td>\n      <td>3</td>\n      <td>20</td>\n      <td>185</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>747</td>\n      <td>80</td>\n      <td>43</td>\n      <td>68</td>\n      <td>123</td>\n      <td>53</td>\n      <td>7</td>\n      <td>150</td>\n      <td>46</td>\n      <td>19</td>\n      <td>147</td>\n      <td>169</td>\n      <td>327</td>\n      <td>176</td>\n      <td>81</td>\n      <td>7</td>\n      <td>14</td>\n      <td>179</td>\n      <td>184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>609</td>\n      <td>87</td>\n      <td>42</td>\n      <td>60</td>\n      <td>116</td>\n      <td>51</td>\n      <td>6</td>\n      <td>150</td>\n      <td>46</td>\n      <td>19</td>\n      <td>141</td>\n      <td>169</td>\n      <td>324</td>\n      <td>171</td>\n      <td>85</td>\n      <td>2</td>\n      <td>14</td>\n      <td>178</td>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>698</td>\n      <td>83</td>\n      <td>42</td>\n      <td>71</td>\n      <td>152</td>\n      <td>64</td>\n      <td>7</td>\n      <td>149</td>\n      <td>45</td>\n      <td>19</td>\n      <td>142</td>\n      <td>172</td>\n      <td>331</td>\n      <td>158</td>\n      <td>74</td>\n      <td>2</td>\n      <td>2</td>\n      <td>184</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>407</td>\n      <td>91</td>\n      <td>38</td>\n      <td>75</td>\n      <td>136</td>\n      <td>53</td>\n      <td>6</td>\n      <td>144</td>\n      <td>47</td>\n      <td>19</td>\n      <td>131</td>\n      <td>165</td>\n      <td>305</td>\n      <td>149</td>\n      <td>69</td>\n      <td>1</td>\n      <td>7</td>\n      <td>186</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>365</td>\n      <td>108</td>\n      <td>54</td>\n      <td>105</td>\n      <td>203</td>\n      <td>62</td>\n      <td>11</td>\n      <td>202</td>\n      <td>33</td>\n      <td>23</td>\n      <td>164</td>\n      <td>216</td>\n      <td>608</td>\n      <td>235</td>\n      <td>68</td>\n      <td>12</td>\n      <td>3</td>\n      <td>190</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>227</td>\n      <td>94</td>\n      <td>35</td>\n      <td>66</td>\n      <td>147</td>\n      <td>62</td>\n      <td>9</td>\n      <td>131</td>\n      <td>50</td>\n      <td>18</td>\n      <td>127</td>\n      <td>159</td>\n      <td>258</td>\n      <td>115</td>\n      <td>66</td>\n      <td>8</td>\n      <td>7</td>\n      <td>196</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>436</td>\n      <td>93</td>\n      <td>42</td>\n      <td>64</td>\n      <td>123</td>\n      <td>51</td>\n      <td>7</td>\n      <td>135</td>\n      <td>51</td>\n      <td>18</td>\n      <td>144</td>\n      <td>164</td>\n      <td>262</td>\n      <td>155</td>\n      <td>78</td>\n      <td>16</td>\n      <td>12</td>\n      <td>185</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>497</td>\n      <td>94</td>\n      <td>43</td>\n      <td>82</td>\n      <td>136</td>\n      <td>54</td>\n      <td>10</td>\n      <td>155</td>\n      <td>43</td>\n      <td>19</td>\n      <td>149</td>\n      <td>176</td>\n      <td>359</td>\n      <td>161</td>\n      <td>74</td>\n      <td>1</td>\n      <td>6</td>\n      <td>186</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>318</td>\n      <td>89</td>\n      <td>37</td>\n      <td>51</td>\n      <td>111</td>\n      <td>54</td>\n      <td>5</td>\n      <td>120</td>\n      <td>56</td>\n      <td>17</td>\n      <td>127</td>\n      <td>138</td>\n      <td>213</td>\n      <td>147</td>\n      <td>82</td>\n      <td>7</td>\n      <td>4</td>\n      <td>181</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>222</td>\n      <td>100</td>\n      <td>50</td>\n      <td>81</td>\n      <td>197</td>\n      <td>67</td>\n      <td>6</td>\n      <td>186</td>\n      <td>34</td>\n      <td>22</td>\n      <td>158</td>\n      <td>206</td>\n      <td>531</td>\n      <td>198</td>\n      <td>74</td>\n      <td>6</td>\n      <td>1</td>\n      <td>197</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>409</td>\n      <td>86</td>\n      <td>38</td>\n      <td>86</td>\n      <td>175</td>\n      <td>60</td>\n      <td>9</td>\n      <td>170</td>\n      <td>39</td>\n      <td>21</td>\n      <td>134</td>\n      <td>191</td>\n      <td>433</td>\n      <td>138</td>\n      <td>68</td>\n      <td>1</td>\n      <td>28</td>\n      <td>191</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>836</td>\n      <td>87</td>\n      <td>45</td>\n      <td>66</td>\n      <td>139</td>\n      <td>58</td>\n      <td>8</td>\n      <td>140</td>\n      <td>47</td>\n      <td>18</td>\n      <td>148</td>\n      <td>168</td>\n      <td>294</td>\n      <td>175</td>\n      <td>73</td>\n      <td>3</td>\n      <td>12</td>\n      <td>188</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>247</td>\n      <td>91</td>\n      <td>39</td>\n      <td>83</td>\n      <td>176</td>\n      <td>59</td>\n      <td>7</td>\n      <td>169</td>\n      <td>39</td>\n      <td>20</td>\n      <td>132</td>\n      <td>190</td>\n      <td>426</td>\n      <td>142</td>\n      <td>67</td>\n      <td>0</td>\n      <td>24</td>\n      <td>192</td>\n      <td>199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "               0           1           2           3           4           5   \\\ncount  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \nmean   424.768670   93.477231   44.599271   81.444444  167.947177   61.630237   \nstd    240.576678    8.164254    6.159060   15.668064   33.700524    8.117065   \nmin      0.000000   73.000000   33.000000   40.000000  104.000000   48.000000   \n25%    224.000000   87.000000   39.000000   70.000000  140.000000   57.000000   \n50%    425.000000   92.000000   44.000000   78.000000  166.000000   61.000000   \n75%    630.000000   99.000000   49.000000   96.000000  194.000000   65.000000   \nmax    845.000000  117.000000   58.000000  110.000000  333.000000  138.000000   \n\n               6           7           8           9           10          11  \\\ncount  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \nmean     8.438980  167.608379   41.231330   20.486339  147.397086  187.739526   \nstd      4.698813   33.239860    7.870487    2.586160   14.470675   31.947601   \nmin      2.000000  112.000000   26.000000   17.000000  118.000000  130.000000   \n25%      6.000000  146.000000   33.000000   19.000000  135.000000  167.000000   \n50%      8.000000  156.000000   43.000000   20.000000  146.000000  178.000000   \n75%     10.000000  197.000000   46.000000   23.000000  159.000000  215.000000   \nmax     52.000000  262.000000   61.000000   28.000000  188.000000  320.000000   \n\n               12          13          14          15          16          17  \\\ncount  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \nmean   433.834244  173.566485   72.566485    6.331512   12.642987  188.912568   \nstd    176.815391   33.015502    7.813850    4.922328    8.872786    6.141549   \nmin    184.000000  112.000000   61.000000    0.000000    0.000000  176.000000   \n25%    317.000000  146.000000   67.000000    2.000000    6.000000  184.000000   \n50%    359.000000  173.000000   71.000000    6.000000   11.000000  189.000000   \n75%    583.000000  197.000000   75.000000    9.000000   19.000000  193.000000   \nmax    998.000000  268.000000  135.000000   22.000000   41.000000  206.000000   \n\n               18  \ncount  549.000000  \nmean   195.448087  \nstd      7.330788  \nmin    181.000000  \n25%    190.000000  \n50%    196.000000  \n75%    201.000000  \nmax    211.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n      <td>549.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>424.768670</td>\n      <td>93.477231</td>\n      <td>44.599271</td>\n      <td>81.444444</td>\n      <td>167.947177</td>\n      <td>61.630237</td>\n      <td>8.438980</td>\n      <td>167.608379</td>\n      <td>41.231330</td>\n      <td>20.486339</td>\n      <td>147.397086</td>\n      <td>187.739526</td>\n      <td>433.834244</td>\n      <td>173.566485</td>\n      <td>72.566485</td>\n      <td>6.331512</td>\n      <td>12.642987</td>\n      <td>188.912568</td>\n      <td>195.448087</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>240.576678</td>\n      <td>8.164254</td>\n      <td>6.159060</td>\n      <td>15.668064</td>\n      <td>33.700524</td>\n      <td>8.117065</td>\n      <td>4.698813</td>\n      <td>33.239860</td>\n      <td>7.870487</td>\n      <td>2.586160</td>\n      <td>14.470675</td>\n      <td>31.947601</td>\n      <td>176.815391</td>\n      <td>33.015502</td>\n      <td>7.813850</td>\n      <td>4.922328</td>\n      <td>8.872786</td>\n      <td>6.141549</td>\n      <td>7.330788</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>73.000000</td>\n      <td>33.000000</td>\n      <td>40.000000</td>\n      <td>104.000000</td>\n      <td>48.000000</td>\n      <td>2.000000</td>\n      <td>112.000000</td>\n      <td>26.000000</td>\n      <td>17.000000</td>\n      <td>118.000000</td>\n      <td>130.000000</td>\n      <td>184.000000</td>\n      <td>112.000000</td>\n      <td>61.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>176.000000</td>\n      <td>181.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>224.000000</td>\n      <td>87.000000</td>\n      <td>39.000000</td>\n      <td>70.000000</td>\n      <td>140.000000</td>\n      <td>57.000000</td>\n      <td>6.000000</td>\n      <td>146.000000</td>\n      <td>33.000000</td>\n      <td>19.000000</td>\n      <td>135.000000</td>\n      <td>167.000000</td>\n      <td>317.000000</td>\n      <td>146.000000</td>\n      <td>67.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>184.000000</td>\n      <td>190.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425.000000</td>\n      <td>92.000000</td>\n      <td>44.000000</td>\n      <td>78.000000</td>\n      <td>166.000000</td>\n      <td>61.000000</td>\n      <td>8.000000</td>\n      <td>156.000000</td>\n      <td>43.000000</td>\n      <td>20.000000</td>\n      <td>146.000000</td>\n      <td>178.000000</td>\n      <td>359.000000</td>\n      <td>173.000000</td>\n      <td>71.000000</td>\n      <td>6.000000</td>\n      <td>11.000000</td>\n      <td>189.000000</td>\n      <td>196.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>630.000000</td>\n      <td>99.000000</td>\n      <td>49.000000</td>\n      <td>96.000000</td>\n      <td>194.000000</td>\n      <td>65.000000</td>\n      <td>10.000000</td>\n      <td>197.000000</td>\n      <td>46.000000</td>\n      <td>23.000000</td>\n      <td>159.000000</td>\n      <td>215.000000</td>\n      <td>583.000000</td>\n      <td>197.000000</td>\n      <td>75.000000</td>\n      <td>9.000000</td>\n      <td>19.000000</td>\n      <td>193.000000</td>\n      <td>201.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>845.000000</td>\n      <td>117.000000</td>\n      <td>58.000000</td>\n      <td>110.000000</td>\n      <td>333.000000</td>\n      <td>138.000000</td>\n      <td>52.000000</td>\n      <td>262.000000</td>\n      <td>61.000000</td>\n      <td>28.000000</td>\n      <td>188.000000</td>\n      <td>320.000000</td>\n      <td>998.000000</td>\n      <td>268.000000</td>\n      <td>135.000000</td>\n      <td>22.000000</td>\n      <td>41.000000</td>\n      <td>206.000000</td>\n      <td>211.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549 entries, 0 to 548\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       549 non-null    int64\n",
      " 1   1       549 non-null    int64\n",
      " 2   2       549 non-null    int64\n",
      " 3   3       549 non-null    int64\n",
      " 4   4       549 non-null    int64\n",
      " 5   5       549 non-null    int64\n",
      " 6   6       549 non-null    int64\n",
      " 7   7       549 non-null    int64\n",
      " 8   8       549 non-null    int64\n",
      " 9   9       549 non-null    int64\n",
      " 10  10      549 non-null    int64\n",
      " 11  11      549 non-null    int64\n",
      " 12  12      549 non-null    int64\n",
      " 13  13      549 non-null    int64\n",
      " 14  14      549 non-null    int64\n",
      " 15  15      549 non-null    int64\n",
      " 16  16      549 non-null    int64\n",
      " 17  17      549 non-null    int64\n",
      " 18  18      549 non-null    int64\n",
      "dtypes: int64(19)\n",
      "memory usage: 81.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Machine Learning pipeline\n",
    "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalizer = preprocessing.MinMaxScaler()\n",
    "X_train_norm_np = normalizer.fit_transform(X_train) # надо данные отнормировать\n",
    "X_train_pd = pd.DataFrame(data=X_train_norm_np)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "X_dum = pd.get_dummies(y_train, drop_first=True)\n",
    "plt.scatter(X_train_norm_np[0],y_train)\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Basic logistic regression\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might use this command to install scikit-plot. \n",
    "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n",
    "# virtual environment instead\n",
    "\n",
    "# ! pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
    "\n",
    "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-12d53ea45258fa82",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eadd4d8a03ae67a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Bagging.\n",
    "Here starts the ensembling part.\n",
    "\n",
    "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
    "\n",
    "We will build two ensembles: of logistic regressions and of decision trees.\n",
    "\n",
    "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
    "\n",
    "\n",
    "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
    "\n",
    "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
    "\n",
    "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
    "\n",
    "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
    "\n",
    "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fc95a2b206bdae1",
     "locked": false,
     "points": 35,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.7. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
    "\n",
    "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Learning curve\n",
    "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
    "\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "name": "pycharm-d7fced36",
   "language": "python",
   "display_name": "PyCharm (ml-mipt)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}